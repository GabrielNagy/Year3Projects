\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amstext}
\usepackage{amsthm}
\usepackage{minted}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Backpropagation in neural networks}
\author{Gabriel Nagy}

\begin{document}
\maketitle

\begin{abstract}
Backpropagation is a method used in artificial neural networks to calculate the error contribution of each neuron after a batch of data (in image recognition, multiple images) is processed. A Neural Network (or artificial neural network) is a collection of interconnected processing elements or nodes. The nodes are termed simulated neurons as they attempt to imitate the functions of biological neurons. The nodes are connected together via links. In this paper we will explain and exemplify the use of backpropagation.
\end{abstract}

\section{How backpropagation works?
}

Initially, a \textit{weight} is assigned at random to each link in order to determine the strength of one nodeâ€™s influence on the other. When the sum of input values reaches a threshold value, the node will produce the output 1 or 0 otherwise. By adjusting the \textit{weights} the desired output can be obtained. This training process makes the network learn. The network, in other words, acquires knowledge in much the same way human brains acquire namely learning from experience. Backpropagation is one of the powerful artificial neural network technique which is used acquire knowledge automatically.

Backpropagation method is the basis for training a supervised \textbf{neural network}. The output is a real value which lies between 0 and 1 based on the sigmoid function. The formula for the output is,
Output = 1 / (1+e-sum)
As the sum increases, the output approaches 1. As the sum decreases, the output approaches 0.

\subsection{The basis of backpropagation networks}
A multilayer network is a kind of neural network which consists of one or more layers of nodes between the input and the output nodes. The input nodes pass values to the hidden layer, which in turn passes to the output layer. A network with a layer of input units, a layer of hidden units and a layer of output units is a two-layer network. A network with two layers of hidden units is a three-layer network, and so on. The multilayer network is the basis for backpropagation network.

As the name implies, there is a backward pass of error to each internal node within the network, which is then used to calculate weight gradients for that node. The network learns by alternately propagating forward the activations and propagating backward the errors as and when they occur.

Backpropagation network can deal with various types of data. It also has the ability to model a complex decision system. If the problem domain involves large amount of data, the network will require to have more input units or hidden units. Consequently this will increase the complexity of the model and also increase its computational complexity. Moreover it takes more time in solving complex problems. In order to overcome this problem multi-backpropagation network is used.

In the beginning of the training process, weights are assigned to the connections at random. The training process is iterative. The training cases are given to the network iteratively. The actual outputs are compared with desired outputs and the errors are calculated. The errors are then propagated back to the network in order to adjust the weights. The training process repeats till the desired outputs are obtained or the error reaches an acceptable level.
\subsection{Types of backpropagation networks}
Static back-propagation is one kind of \textit{backpropagation networks} that produces a mapping of a static input to a static output. These networks can solve static classification problems such as \textit{optical character recognition} (OCR). Recurrent Backpropagation is another kind of type used for fixed-point learning. NeuroSolutions, for example, is software that has this ability. In recurrent backpropagation, activations are fed forward until a fixed value is achieved. There after the error is computed and propagated backwards. The difference between static and recurrent backpropagation is that the mapping is instantaneous in static back-propagation while it is not in the case of latter type. Moreover training a network using fixed-point learning is more difficult than with static backpropagation.
\subsection{Application of backpropagation}
The researchers, Thomas Riga, Angelo Cangelosi (University of Plymouth) and Alberto Greco (University of Genoa), have developed a model for grounding of symbol. It assumes the brain as a symbol system and explains cognition as a manipulation of symbols governed by rules.

The symbol grounding problem is nothing but connecting meaning to the symbols or images of objects received from input stimuli. The model uses two learning algorithms: Kohonen Self-Organizing Feature Map and backpropagation algorithm.

To perform the tasks, it has two modules and a retina for input. The first module uses Kohonen Self-Organizing Feature Map and categorizes the images projected on the retina. It expresses the intrinsic order of the stimulus set in a bi-dimensional matrix known as activation matrix.

The second module relates visual input, symbolic input and output stimuli. Now it uses backpropagation algorithm for learning. The error in the output is computed with respect to the training set and is sent back to input unit and the weight distribution is corrected in order to get the correct output. In this process, the symbols which are grounded constitute the knowledge. The knowledge so acquired is then used to generate and describe new meanings for the symbols.
\section{Implementation}
\subsection{Algorithm}
Let $N$ be a neural network with $e$ connections, $m$ inputs, and $n$ outputs.

Below,  $x_1, x_2, \ldots$ will denote vectors in $\mathbb{R}^m$, $y_1, y_2, \ldots$ vectors in $\mathbb{R}^n$, and $w_0, w_1, w_2, \ldots$ vectors in $\mathbb{R}^e$. These are called \textit{inputs}, \textit{outputs} and \textit{weights} respectively.

The neural network corresponds to a function $y = f_N (w,x)$  which, given a weight $w$, maps an input $x$ to an output $y$.

The optimization takes as input a sequence of \textit{training examples} $(x_1, y_1),\ldots,(x_p,y_p)$ and produces a sequence of weights $w_0, w_1, \ldots, w_p$ starting from some initial weight $w_0$, usually chosen at random.

These weights are computed in turn: first compute $w_i$ using only $(x_i, y_i, w_{i-1})$  for $i=1,\ldots,p$. The output of the algorithm is them $w_p$, giving us a new function $x\rightarrow f_N(w_p,x)$. The computation is the same in each step, hence only the case $i=1$ is described.

Calculating $w_1$ from $(x_1, y_1, w_0)$ is done by considering a variable weight $w$ and applying gradient descent to the function $w\rightarrow E(f_N(w, x_1), y_1)$ to find a local minimum, starting at $w=w_0$.

This makes $w_1$ the minimizing weight found by gradient descent.

\subsection{Algorithm in code}
To implement the algorithm above, explicit formulas are required for the gradient of the function $w\rightarrow E(f_N(w,x),y)$ where the function is $E(y,y')=|y-y'|^2$.

The learning algorithm can be divided into two phases: propagation and weight update.
\subsubsection{Phase 1: Propagation}
Each propagation involves the following steps:
\begin{enumerate}
\item Propagation forward through the network to generate the output value(s)
\item Calculation of the cost (error term)
\item Propagation of the output activations back through the network using the training pattern target in order to generate the deltas (the difference between the targeted and actual output values) of all output and hidden neurons.
\end{enumerate}
\subsubsection{Phase 2: Weight update}
For each weight, the following steps must be followed:
\begin{enumerate}
\item The weight's output delta and input activation are multiplied to find the gradient of the weight.
\item A ratio (percentage) of the weight's gradient is subtracted from the weight.
\end{enumerate}

This ratio (percentage) influences the speed and quality of learning; it is called the\textit{ learning rate}. The greater the ratio, the faster the neuron trains, but the lower the ratio, the more accurate the training is. The sign of the gradient of a weight indicates whether the error varies directly with, or inversely to, the weight. Therefore, the weight must be updated in the opposite direction, "descending" the gradient.

Learning is repeated (on new batches) until the network performs adequately.

\subsubsection{Pseudocode}
The following is pseudocode for a stochastic gradient descent algorithm for training a three-layer network (only one hidden layer):
\begin{minted}{c}
  initialize network weights (often small random values)
  do
     forEach training example named ex
        prediction = neural-net-output(network, ex)  // forward pass
        actual = teacher-output(ex)
        compute error (prediction - actual) at the output units
        compute delta_wh for all weights from hidden layer to output layer  // backward pass
        compute delta_wi for all weights from input layer to hidden layer   // backward pass cont'd
        update network weights // input layer not modified by error estimate
  until all examples classified correctly or another stopping criterion satisfied
  return the network
 \end{minted}

The lines labeled "backward pass" can be implemented using the backpropagation algorithm, which calculates the gradient of the error of the network regarding the network's modifiable weights\cite{Werbos:1994:RBO:175610}.

\subsection{Example implementation}
\subsubsection{Overview}
For the purpose of an example, we're going to use a neural network with two inputs, two hidden neurons, two output neurons. Additionally, the hidden and output neurons will include a bias.\cite{Mazur}

In order to have some numbers to work with, we assign some arbitrary values to the weights, biases, and training inputs/outputs such that $i_1=0.05, i_2=0.1, o_1=0.01, o_2=0.99, b_1=0.35, b_2=0.6$ and $w_1=0.15, w_2=0.2, w_3=0.25, w_4=0.3, w_5=0.4, w_6=0.45, w_7=0.5, w_8=0.55$.

The goal of backpropagation is to optimize the weights so that the neural network can learn how to correctly map arbitrary inputs to outputs.

For the rest of this tutorial weâ€™re going to work with a single training set: given inputs 0.05 and 0.10, we want the neural network to output 0.01 and 0.99.

\subsubsection{The Forward Pass}
To begin, let's see what the neural network currently predicts given the weights and biases above inputs of 0.05 and 0.1. To do this, we'll feed the inputs forward through the network.

We figure out the \textit{total net input} to each hidden layer neuron, \textit{squash }the total net input using an \textit{activation function }(here we use the \textit{logistic function}), then repeat the process with the output layer neurons.

Here is the total net input calculation for $h_1$:

$net_{h_1}=w_1*i_1+w_2*i_2+b_1*1$ 

$net_{h_1}=0.15*0.05+0.2*0.1+0.35*1=0.3775$ 

We then squash it using the logistic function to get the output of ${h_1}$:

$out_{h_1} = \frac{1}{1+e^{-net_{h_1}}}=\frac{1}{1+e^{-0.3775}}=0.593269992$ 

Carrying out the same process for $h_2$ we get:

$out_{h_2}=0.596884378$

\bigskip
We repeat this process for the output layer neurons, using the output from the hidden layer neurons as inputs. Here's the output for $o_1$:

$net_{o_1}=w_5*out_{h_1}+w_6*out_{h_2}+b_2*1$

$net_{o_1}=0.4*0.593269992+0.45*0.596884378+0.6*1=1.105905967$

$out_{o_1}=\frac{1}{1+e^{-net_{o_1}}}=\frac{1}{1+e^{-1.105905967}}=0.75136507$

Carrying out the same process for $o_2$ we get:

$out_{o_2}=0.772928465$

\bigskip
\textbf{Calculating the Total Error}

We can now calculate the error for each output neuron using the squared error function and sun them to get the total error:

$E_{total}=\sum\frac{1}{2}(target-output)^2$

The $\frac{1}{2}$ is included so that the exponent is cancelled when we differentiate later on. The result is eventually multiplied by a learning rate so it doesn't matter that we introduce a constant here.


\bigskip For example, the target output for $o_1$ is 0.01 but the neural network output is 0.75136507, therefore its error is:

$E_{o_1}=\frac{1}{2}(target_{o_1}-out_{o_1})^2=\frac{1}{2}(0.01-0.75136507)^2=0.274811083$

\bigskip
Repeating the process for $o_2$ (remembering that the target is 0.99) we get:

$E_{o_2}=0.023560026$

The total error for the neural network is the sum of these errors:

$E_{total}=E_{o_1}+E_{o_2}=0.274811083+0.023560026=0.298371109$

\subsubsection{The Backwards Pass}
Our goal with backpropagation is to update each of the weights in the network so that they cause the actual output to be closer to the targeted output, thereby minimizing the error for each output neuron and the network as a whole.

\bigskip
\textbf{Output Layer}

Consider $w_5$. We want to know how much a change in $w_5$ affects the total error, $\frac{\partial E_{total}}{\partial w_5}$.

By applying the chain rule we know that:

$\frac{\partial E_{total}}{\partial w_5}=\frac{\partial E_{total}}{\partial out_{o_1}}*\frac{\partial out_{o_1}}{\partial net_{o_1}}*\frac{\partial net_{o_1}}{\partial w_5}$ 

We need to figure out each piece in this equation. First, how much does the total error change with respect to the output?

$E_{total} = \frac{1}{2}(target_{o_1}-out_{o_1})^2 + \frac{1}{2}(target_{o_2}-out_{o_2})^2$

$\frac{\partial E_{total}}{\partial out_{o_1}} = 2*\frac{1}{2}(target_{o_1}-out_{o_1})^{2-1}*-1+0$

$\frac{\partial E_{total}}{\partial out_{o_1}} = -(target_{o_1}-out_{o_1})=-(0.01-0.75136507)=0.74136507$

\bigskip
Next, how much does the output of $o_1$ change with respect to its total net input? The partial derivative of the logistic function is the output multiplied by 1 minus the output:

$out_{o_1}=\frac{1}{1+e^{-net_{o_1}}}$

$\frac{\partial out_{o_1}}{\partial net_{o_1}}=out_{o_1}(1-out_{o_1})=0.75136507(1-0.75136507)=0.186815602$ 

Finally, how much does the total net input of $o_1$ change with respect to $w_5$?

$net_{o_1}=w_5*out_{h_1}+w_6*out_{h_2}+b_2*1$

$\frac{\partial net_{o_1}}{\partial w_5}=1*out_{h_1}*w_5^{(1-1)}+0+0=out_{h_1}=0.593269992$ 

Putting it all together:

$\frac{\partial E_{total}}{\partial w_5} = \frac{\partial E_{total}}{\partial out_{o_1}} * \frac{\partial out_{o_1}}{\partial net_{o_1}}*\frac{\partial net_{o_1}}{\partial w_5}$

$\frac{\partial E_{total}}{\partial w_5} = 0.74136507*0.186815602*0.593269992=0.082167041$

To decrease the error, we then subtract this value from the current weight (optionally multiplied by some learning rate, $\eta$, which we'll set to 0.5):

$w_5^+=w_5-\eta*\frac{\partial E_{total}}{\partial w_5} = 0.4-0.5*0.082167041=0.35891648$

\bigskip
We repeat this process for the new weights $w_6$, $w_7$, $w_8$:

$w_6^+=0.408666186$

$w_7^+=0.511301270$

$w_8^+=0.561370121$

We perform the actual updates in the neural network \textit{after} we have the new weights leading into the hidden layer neurons (i.e.: we use the original weights, not the updated weights, when we continue the backpropagation algorithm below).

\bigskip
\textbf{Hidden Layer}

Next, we'll continue the backwards pass by calculating new values for $w_1$, $w_2$, $w_3$ and $w_4$. What we need to figure out is:

$\frac{\partial E_{total}}{\partial w_1} = \frac{\partial E_{total}}{\partial out_{h_1}} * \frac{\partial out_{h_1}}{\partial net_{h1}} * \frac{\partial net_{h1}}{\partial w_1}$

The process we use is similar to the output layer, but slightly different to account for the fact that the output of each hidden layer neuron contributes to the output (and therefore error) of multiple output neurons. We know that $out_{h_1}$ affects both $out_{o_1}$ and $out_{o_2}$ therefore the $\frac{\partial E_{total}}{\partial out_{h_1}}$ needs to take into consideration its effect on both output neurons:

$\frac{\partial E_{total}}{\partial out_{h_1}} = \frac{\partial E_{o_1}}{\partial out_{h_1}} + \frac{\partial E_{o_2}}{\partial out_{h_1}}$

\bigskip
Starting with $\frac{\partial E_{o_1}}{\partial out_{h_1}}$:

$\frac{\partial E_{o_1}}{\partial out_{h_1}} = \frac{\partial E_{o_1}}{\partial net_{o_1}} * \frac{\partial net_{o_1}}{\partial out_{h_1}}$

We can calculate $\frac{\partial E_{o_1}}{\partial net_{h_1}}$ using values we computed earlier:

$\frac{\partial E_{o_1}}{\partial net_{o_1}} = \frac{\partial E_{o_1}}{\partial out_{o_1}}*\frac{\partial out_{o_1}}{\partial net_{o_1}}=0.74136507*0.186815602=0.138498562$ 

And $\frac{\partial net_{o_1}}{\partial out_{h_1}}$ is equal to $w_5$:

$net_{o_1}=w_5*out_{h_1}+w_6*out_{h_2}+b_2*1$

$\frac{\partial net_{o_1}}{\partial out_{h_1}} = w_5 = 0.4$

\bigskip
Plugging them in:

$\frac{\partial E_{o_1}}{\partial out_{h_1}} = \frac{\partial E_{o_1}}{\partial net_{o_1}} * \frac{\partial net_{o_1}}{\partial out_{h_1}}=0.138498562*0.4=0.055399425$

Following the same process for $\frac{\partial E_{o_2}}{\partial out_{h_1}}$, we get:

$\frac{\partial E_{o_2}}{\partial out_{h_1}}=-0.019049119$

Therefore:

$\frac{\partial E_{total}}{\partial out_{h_1}}=\frac{\partial E_{o_1}}{\partial out_{h_1}}+\frac{\partial E_{o_2}}{\partial out_{h_1}} = 0.55399425+-0.019049119=0.036350306$

\bigskip
Now that we have $\frac{\partial E_{total}}{\partial out_{h_1}}$, we need to figure out $\frac{\partial out_{h_1}}{\partial net_{h_1}}$ and then $\frac{\partial net_{h_1}}{\partial w}$ for each weight:

$out_{h_1} = \frac{1}{1+e^{-net_{h_1}}}$

$\frac{\partial out_{h_1}}{\partial net_{h_1}} = out_{h_1}(1-out_{h_1})=0.59326999(1-0.59326999)=0.241300709$

\bigskip
We calculate the partial derivative of the total net input to $h_1$ with respect to $w_1$, the same as we did for the output neuron:

$net_{h_1} = w_1*i_1+w_3*i_2+b_1*1$

$\frac{\partial net_{h_1}}{\partial w_1} = i_1=0.05$

\bigskip
Putting it all together:

$\frac{\partial E_{total}}{\partial w_1} = \frac{\partial E_{total}}{\partial out_{h_1}} * \frac{\partial out_{h_1}}{\partial net_{h_1}} * \frac{\partial net_{h_1}}{\partial w_1}$

$\frac{\partial E_{total}}{\partial w_1} = 0.036350306*0.241300709*0.05=0.000438568$

We can now update $w_1$:

$w_1^+=w_1-\eta * \frac{\partial E_{total}}{\partial w_1} = 0.15-0.5*0.000438568=0.149780716$

Repeating this for $w_2$, $w_3$, and $w_4$:

$w_2^+=0.19956143$
$w_3^+=0.24975114$
$w_4^+=0.29950229$

\subsubsection{Conclusion}
Finally, we have updated all of the weights. When fed the 0.05 and 0.1 inputs, the error on the network was 0.298371109.

After this first round of backpropagation, the total error is now down to 0.291027924. It might not seem like much, but after repeating this process 10,000 times, for example, the error plummets to 0.0000351085. At this point, when we feed forward 0.05 and 0.1, the two outputs neurons generate 0.015912196 (vs 0.01 target) and 0.984065734 (vs 0.99 target).


\bibliographystyle{alpha}
\bibliography{sample}

\end{document}